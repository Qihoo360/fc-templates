# 应用介绍

本案例是将 ollama ，快速创建并部署到函数计算 FC 。

Ollama是一个开源的大型语言模型服务工具，它帮助用户快速在本地运行大模型。通过简单的安装指令，用户可以执行一条命令就在本地运行开源大型语言模型，如Llama 2。Ollama极大地简化了在Docker容器内部署和管理LLM的过程，使得用户能够快速地在本地运行大型语言模型。

通过 Serverless 开发平台，您只需要几步，就可以体验 ollama 框架，并享受 Serverless 架构带来的降本提效的技术红利

* [代码](https://github.com/Qihoo360/fc-templates/tree/feature/fc-app-test/applications/ArtificialIntelligence/ollama/src)

* [官方网站](https://ollama.com)

# 前期准备

使用该项目，您需要有开通以下服务并拥有对应权限：

* 函数计算

# 部署 & 体验

* 通过 智汇云官网 -> 产品列表 -> Serverless开发 ->函数计算 FC，部署该应用。

## 配置依赖

无

# 应用的使用说明

在控制台完成业务功能部署，完成会出现触发器url。
此时，使用浏览器或者 curl 工具， 就可以对触发器url进行请求。

